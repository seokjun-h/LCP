{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shap\n",
    "\n",
    "# 시드 고정\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/home/aibig25/hong_sj/trb/num.csv')\n",
    "data = data.fillna(0)\n",
    "\n",
    "unique_ids = data['sequence_ID'].unique()\n",
    "train_ids, test_ids = train_test_split(unique_ids, test_size=41, random_state=42)\n",
    "train_data = data[data['sequence_ID'].isin(train_ids)]\n",
    "test_data = data[data['sequence_ID'].isin(test_ids)]\n",
    "\n",
    "independent_vars = data.columns.difference(['center_x', 'center_y','center_x_ma','center_y_ma', 'ID', 'frame', \"LC\"])\n",
    "dependent_vars = ['center_y_ma']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_data[independent_vars] = scaler.fit_transform(train_data[independent_vars])\n",
    "test_data[independent_vars] = scaler.transform(test_data[independent_vars])\n",
    "\n",
    "X_train = train_data[independent_vars]\n",
    "y_train = train_data[dependent_vars]\n",
    "\n",
    "X_test = test_data[independent_vars]\n",
    "y_test = test_data[dependent_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 및 예측 시퀀스 길이 정의\n",
    "input_sequence_length = 120\n",
    "output_sequence_length = 90\n",
    "\n",
    "def create_sequences(data, input_sequence_length, output_sequence_length):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data) - input_sequence_length - output_sequence_length + 1):\n",
    "        X.append(data.iloc[i:(i + input_sequence_length)][independent_vars].values)\n",
    "        y.append(data.iloc[(i + input_sequence_length):(i + input_sequence_length + output_sequence_length)][dependent_vars].values)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = create_sequences(train_data, input_sequence_length, output_sequence_length)\n",
    "X_test, y_test = create_sequences(test_data, input_sequence_length, output_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 텐서로 변환\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
    "\n",
    "# 데이터 로더 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim, num_heads, num_encoder_layers, num_decoder_layers, output_dim):\n",
    "        super(TrajectoryTransformer, self).__init__()\n",
    "        self.model_dim = model_dim\n",
    "        \n",
    "        self.encoder = nn.Linear(input_dim, model_dim)\n",
    "        self.pos_encoder = PositionalEncoding(model_dim)\n",
    "        self.tgt_linear = nn.Linear(1, model_dim)\n",
    "        \n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=model_dim,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=model_dim * 4,\n",
    "            dropout=0.1\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Linear(model_dim, output_dim)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src = self.encoder(src)\n",
    "        src = src * math.sqrt(self.model_dim)\n",
    "        src = self.pos_encoder(src.permute(1, 0, 2))\n",
    "\n",
    "        tgt = tgt.squeeze(-1)\n",
    "        original_shape = tgt.shape\n",
    "        tgt = tgt.reshape(-1, 1)\n",
    "        tgt = self.tgt_linear(tgt)\n",
    "        tgt = tgt.view(original_shape[0], original_shape[1], -1)\n",
    "        tgt = tgt * math.sqrt(self.model_dim)\n",
    "        tgt = self.pos_encoder(tgt.permute(1, 0, 2))\n",
    "\n",
    "        output = self.transformer(src, tgt)\n",
    "        output = self.decoder(output.permute(1, 0, 2))\n",
    "\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, model_dim, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, model_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, model_dim, 2).float() * (-math.log(10000.0) / model_dim))\n",
    "        self.encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.encoding = self.encoding.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', self.encoding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "input_dim = len(independent_vars)\n",
    "output_dim = len(dependent_vars)\n",
    "model_dim = 512\n",
    "num_heads = 4\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "\n",
    "model = TrajectoryTransformer(input_dim, model_dim, num_heads, num_encoder_layers, num_decoder_layers, output_dim)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "\n",
    "# 옵티마이저와 손실 함수\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 입력 데이터 (배치 크기: 1, 시간 단계: 120, 변수: 24)\n",
    "example_src = torch.tensor(X_train[:10], dtype=torch.float32)\n",
    "example_tgt = torch.tensor(y_train[:10], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provided model function fails when applied to the provided data set.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1250 into shape (2,120,25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m background_data \u001b[38;5;241m=\u001b[39m X_train[:\u001b[38;5;241m1200\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(independent_vars))  \u001b[38;5;66;03m# 배경 데이터로 사용할 데이터셋\u001b[39;00m\n\u001b[1;32m     20\u001b[0m background_data_summary \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mkmeans(background_data, \u001b[38;5;241m50\u001b[39m)  \u001b[38;5;66;03m# K-means를 사용하여 50개의 샘플로 요약\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKernelExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_predict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_data_summary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# SHAP 값 계산\u001b[39;00m\n\u001b[1;32m     25\u001b[0m X_test_sample \u001b[38;5;241m=\u001b[39m X_test[:input_sequence_length\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(independent_vars))  \u001b[38;5;66;03m# 10개의 시퀀스를 선택\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/solar/lib/python3.8/site-packages/shap/explainers/_kernel.py:96\u001b[0m, in \u001b[0;36mKernelExplainer.__init__\u001b[0;34m(self, model, data, feature_names, link, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m convert_to_model(model, keep_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_index)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m convert_to_data(data, keep_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_index)\n\u001b[0;32m---> 96\u001b[0m model_null \u001b[38;5;241m=\u001b[39m \u001b[43mmatch_model_to_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# enforce our current input type limitations\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, DenseData) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, SparseData), \\\n\u001b[1;32m    100\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShap explainer only supports the DenseData and SparseData input currently.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/solar/lib/python3.8/site-packages/shap/utils/_legacy.py:136\u001b[0m, in \u001b[0;36mmatch_model_to_data\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m    134\u001b[0m         out_val \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mf(data\u001b[38;5;241m.\u001b[39mconvert_to_df())\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m         out_val \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvided model function fails when applied to the provided data set.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 10\u001b[0m, in \u001b[0;36mmodel_predict\u001b[0;34m(input_data)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_samples \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m0\u001b[39m, output_sequence_length))  \u001b[38;5;66;03m# 입력 데이터가 너무 작을 경우 예측값을 0으로 반환\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_sequence_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindependent_vars\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     12\u001b[0m     dummy_tgt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((input_tensor\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), output_sequence_length, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1250 into shape (2,120,25)"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "# SHAP 분석\n",
    "def model_predict(input_data):\n",
    "    model.eval()\n",
    "    # 전체 시퀀스 길이에 맞게 데이터 크기 조정\n",
    "    num_samples = input_data.shape[0] // len(independent_vars)\n",
    "    if num_samples == 0:\n",
    "        return np.zeros((0, output_sequence_length))  # 입력 데이터가 너무 작을 경우 예측값을 0으로 반환\n",
    "    input_tensor = torch.tensor(input_data.reshape(num_samples, input_sequence_length, len(independent_vars)), dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        dummy_tgt = torch.zeros((input_tensor.size(0), output_sequence_length, 1)).to(device)\n",
    "        predictions = model(input_tensor, dummy_tgt)\n",
    "    # 예측 결과를 2차원으로 변환하여 반환\n",
    "    return predictions.cpu().numpy().reshape(num_samples * output_sequence_length, -1)\n",
    "\n",
    "# SHAP Explainer 준비\n",
    "# 2차원으로 입력 데이터를 변환하여 준비\n",
    "background_data = X_train[:1200].reshape(-1, len(independent_vars))  # 배경 데이터로 사용할 데이터셋\n",
    "background_data_summary = shap.kmeans(background_data, 50)  # K-means를 사용하여 50개의 샘플로 요약\n",
    "\n",
    "explainer = shap.KernelExplainer(model_predict, background_data_summary.data)\n",
    "\n",
    "# SHAP 값 계산\n",
    "X_test_sample = X_test[:input_sequence_length*10].reshape(-1, len(independent_vars))  # 10개의 시퀀스를 선택\n",
    "shap_values = explainer.shap_values(X_test_sample, nsamples=100)\n",
    "\n",
    "# SHAP 값 시각화 (예: 첫 번째 샘플의 60번째 시점)\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value, shap_values[59], X_test_sample[59])\n",
    "\n",
    "# 전체 시퀀스에 대한 SHAP 값 요약 플롯\n",
    "shap.summary_plot(shap_values, X_test_sample)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
